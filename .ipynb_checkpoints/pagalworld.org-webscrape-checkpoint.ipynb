{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------pagalworld.org-webscraper---------\n",
      "\n",
      "Enter Download Location : \n",
      "C:\n",
      "Enter Search : \n",
      "https://www.google.com/search?q=+site%3Apagalworld.org\n"
     ]
    }
   ],
   "source": [
    "chunk_size=1024\n",
    "print(\"----------pagalworld.org-webscraper---------\")\n",
    "location=input(\"\\nEnter Download Location : \")\n",
    "if(location==\"\"):\n",
    "    location=\"C:\"\n",
    "print(location)\n",
    "q=input(\"Enter Search : \")+\" site:pagalworld.org\"\n",
    "url = \"https://www.google.com/search?q=\"+urllib.parse.quote_plus(q)\n",
    "print(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=requests.get(url)\n",
    "soup = BeautifulSoup(r.content,\"html.parser\")\n",
    "res = soup.find_all(\"h3\",{\"class\":\"r\"})\n",
    "raw_links=[]\n",
    "links=[]\n",
    "for i in res:\n",
    "    raw_links.append(i.find(\"a\")[\"href\"])\n",
    "qresnames=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadfile(url):\n",
    "    songdlpage=requests.get(url)\n",
    "    soupdl =BeautifulSoup(songdlpage.content,\"html.parser\")\n",
    "    songdllinks=soupdl.find_all(\"a\",{\"class\":\"dbutton\"})\n",
    "    for c,link in enumerate(songdllinks):\n",
    "        print(c,link.find(\"span\").text,sep=\"\\t\")\n",
    "    ch=int(input(\"Choose a file : \"))\n",
    "    url=str(songdllinks[ch][\"href\"])\n",
    "    r=requests.get(url,stream=True)\n",
    "    r.headers['Content-Length']\n",
    "    size=int(r.headers['Content-Length'])\n",
    "    filename = location+\"\\\\\"+str(songdllinks[ch][\"href\"]).split('/')[-1]\n",
    "    with open(filename,'wb') as f:\n",
    "        for data in tqdm(iterable = r.iter_content(chunk_size=chunk_size), total = size/chunk_size , unit = 'KB'):\n",
    "            f.write(data)\n",
    "    print(\"Download Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileshtml(url):\n",
    "    soup = BeautifulSoup(requests.get(url).content,\"html.parser\")\n",
    "    res=soup.find_all(\"div\",{\"class\":\"listbox\"})\n",
    "    print(\"\\n----------------\")\n",
    "    print(soup.find(\"h1\",{\"class\":\"title\"}).text)\n",
    "    print(\"----------------\\n\")\n",
    "    c=0\n",
    "    for x,i in enumerate(res):\n",
    "        print(x,i.find(\"h2\").text)\n",
    "        c+=1\n",
    "    if(str(type(soup.find(\"li\",{\"class\":\"next\"})))==\"<class 'bs4.element.Tag'>\"):\n",
    "        print(\"\\n-------------------\\n98 : Previous\\n99 : Next\")\n",
    "    ch = input(\"Enter Choice : \")\n",
    "    if(int(ch)==99):\n",
    "        nextlink=soup.find_all(\"li\",{\"class\":\"next\"})\n",
    "        if(str(type(nextlink[0].find(\"span\")))==\"<class 'bs4.element.Tag'>\"):\n",
    "            print(\"\\n---------\\nLast Page\\n---------\")\n",
    "            fileshtml(url)\n",
    "        else:\n",
    "            url = \"https://pagalworld.org\"+nextlink[0].find(\"a\")[\"href\"]\n",
    "            fileshtml(url)\n",
    "    if(int(ch)==98):\n",
    "        prevlink=soup.find_all(\"li\",{\"class\":\"prev\"})\n",
    "        if(str(type(prevlink[0].find(\"span\")))==\"<class 'bs4.element.Tag'>\"):\n",
    "            print(\"\\n---------\\nFirst Page\\n---------\")\n",
    "            fileshtml(url)\n",
    "        else:\n",
    "            url = \"https://pagalworld.org\"+prevlink[0].find(\"a\")[\"href\"]\n",
    "            fileshtml(url)\n",
    "    if(int(ch) in range(0,c)):\n",
    "        url=\"https://pagalworld.org\"+str(res[int(ch)].find(\"a\")[\"href\"])\n",
    "        print(url)\n",
    "        downloadfile(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching...Please wait!\n",
      "\n",
      "0--TOP Songs\n",
      "1--collection3\n",
      "2--MP4\n",
      "3--MUSIC\n",
      "4--Raajneeti\n",
      "5--Citylights\n",
      "6--Ringtones\n",
      "7--Aisha(2010)\n",
      "8--mere_haath_mein(PagalWorld.com) mp3 song Download PagalWorld.com\n",
      "Enter your choice  : 0\n",
      "You Have chosen : TOP Songs\n"
     ]
    }
   ],
   "source": [
    "print(\"Searching...Please wait!\\n\")\n",
    "for c,i in enumerate(raw_links):\n",
    "    try:\n",
    "        links.append(\"https://\"+re.search(r'https://(.*)(?<=.html)',i).group(1))\n",
    "        qresult=requests.get(\"https://\"+re.search(r'https://(.*)(?<=.html)',i).group(1))\n",
    "        soup = BeautifulSoup(qresult.content,\"html.parser\")\n",
    "        qresnames.append(soup.find(\"h1\",{\"class\":\"title\"}).text)\n",
    "    except AttributeError:\n",
    "        continue\n",
    "for c,i in enumerate(qresnames):\n",
    "    print(c,i,sep=\"--\")\n",
    "ch = int(input(\"Enter your choice  : \"))\n",
    "print(\"You Have chosen : {}\".format(qresnames[ch]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://pagalworld.org/top-songs.html',\n",
       " 'https://pagalworld.org/collection3/files.html',\n",
       " 'https://pagalworld.org/mp4/list.html',\n",
       " 'https://pagalworld.org/music/list.html',\n",
       " 'https://pagalworld.org/raajneeti/files.html',\n",
       " 'https://pagalworld.org/citylights/files.html',\n",
       " 'https://pagalworld.org/ringtones/list.html',\n",
       " 'https://pagalworld.org/aisha2010/files.html',\n",
       " 'https://pagalworld.org/merehaathmeinpagalworldcom/download.html']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dltype = links[ch].split(\"/\")[-1]\n",
    "if(dltype==\"files.html\"):\n",
    "    fileshtml(str(links[ch]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t\n",
      "Download Original MP4\n",
      "Size 19.15 MB\n",
      "\n",
      "Choose a file : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18701KB [00:04, 4138.50KB/s]                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download Complete!\n"
     ]
    }
   ],
   "source": [
    "if(dltype==\"download.html\"):\n",
    "    downloadfile(str(links[ch]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlpage=requests.get(str(links[ch]))\n",
    "soupdl=BeautifulSoup(dlpage.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(latestupdates[ch].find(\"h3\").text+\"\\n----------------\")\n",
    "ziplinks = soupdl.find_all(\"a\",{\"class\":\"dbutton\"})\n",
    "songlinks = soupdl.find_all(\"div\",{\"class\":\"listbox\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "for zipfile in ziplinks:\n",
    "    print(c,zipfile.find(\"span\").text,sep=\"\\t\")\n",
    "    c+=1\n",
    "for songfile in songlinks:\n",
    "    print(c,songfile.find(\"h2\").text,sep=\"\\t\")\n",
    "    c+=1\n",
    "ch=int(input(\"Select a file to download : \"))\n",
    "location= input(\"Enter Directory : \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(ch==0 or ch==1):\n",
    "    url=str(ziplinks[ch][\"href\"])\n",
    "    r=requests.get(url,stream=True)\n",
    "    r.headers['Content-Length']\n",
    "    size=int(r.headers['Content-Length'])\n",
    "    filename = location+\"\\\\\"+str(ziplinks[ch][\"href\"]).split('/')[-1]\n",
    "    with open(filename,'wb') as f:\n",
    "        for data in tqdm(iterable = r.iter_content(chunk_size=chunk_size), total = size/chunk_size , unit = 'KB'):\n",
    "            f.write(data)\n",
    "    print(\"Download Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(ch in range(2,c)):\n",
    "    url=\"https://pagalworld.org\"+songlinks[(ch-2)].find(\"a\")[\"href\"]\n",
    "    downloadfile(url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
